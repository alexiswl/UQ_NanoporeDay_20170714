{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A novel approach to Plasmid assembly\n",
    "\n",
    "#### Contents:\n",
    "Novel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get directory\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import subprocess\n",
    "import shutil\n",
    "RUN_DIR = os.getenv(\"RUN_DIR\")\n",
    "PRESENTATION_DIR = os.getenv(\"PRESENTATION_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED\n"
     ]
    }
   ],
   "source": [
    "# Create sample class\n",
    "class Sample:\n",
    "    \"\"\"The sample class is used to define all the files used in the pipeline.\n",
    "       Both Inputs and Outputs. We can use this class object to run our pipeline multiple times\n",
    "       with different setting without having to write multiple sets of code.\"\"\"\n",
    "    def __init__(self, barcode, name, description, fastq_file):\n",
    "        self.name = name\n",
    "        self.barcode = barcode\n",
    "        self.description=description\n",
    "        # Get raw data (fastq files)\n",
    "        self.fastq_path = os.path.join(SUBDIRS[\"fastq\"], fastq_file)\n",
    "        self.fastq_file = fastq_file\n",
    "        # Set pauvre plot output file\n",
    "        self.pauvre_output_plot = os.path.join(SUBDIRS[\"pauvre\"], self.fastq_file.replace(\".fastq\", \".png\"))\n",
    "        # Set trimmed files\n",
    "        self.fastq_file_trimmed = os.path.join(SUBDIRS[\"trimmed\"], self.name+\".trimmed.fastq\")\n",
    "        self.trimmed_logs = os.path.join(SUBDIRS[\"trimmed\"], self.name+\".trimmed.log\")\n",
    "        # Canu related files\n",
    "        self.est_genome_length = 0\n",
    "        self.canu_log_output = os.path.join(SUBDIRS[\"canu\"], self.sample, self.name+\".stderr.log\")\n",
    "        self.canu_tig_info_file = os.path.join(SUBDIRS[\"canu\"], self.sample, self.name+\".contigs.layout.tigInfo\")\n",
    "        self.canu_contig_file = os.path.join(SUBDIRS[\"canu\"], self.sample, self.name+\".contigs.fasta\")\n",
    "        self.canu_trimmed_corrected_reads = os.path.join(SUBDIRS[\"canu\"], self.sample, self.name+\".trimmedReads.fasta.gz\")\n",
    "        self.canu_unassembled_fasta_file = os.path.join(SUBDIRS[\"canu\"], self.sample, self.name+\".unassembled.fasta.\"\n",
    "        # Circlator related files\n",
    "        self.circlator_output_prefix = os.path.join(SUBDIRS[\"circlator\"], self.sample, self.sample)\n",
    "        self.circlator_output_fasta = os.path.join(SUBDIRS[\"circlator\"], self.sample, self.sample+\".circularise.fasta\")\n",
    "        # Alignment related files\n",
    "        self.sam_file = os.path.join(SUBDIRS[\"alignment\"], self.sample, self.sample+\".sam\")\n",
    "        self.bam_file = os.path.join(SUBDIRS[\"alignment\"], self.sample, self.sample+\".bam\")\n",
    "        self.bai_file = os.path.join(SUBDIRS[\"alignment\"], self.sample, self.sample+\".bai\")\n",
    "        # MiSeq data for hybrid assemblies\n",
    "        self.short_read_dir = os.path.join(SUBDIRS[\"illumina_data\"], self.sample)\n",
    "        self.short_read_fastq1_file = [fastq_file for fastq_file in os.listdir(self.short_read_dir)\n",
    "                                       if fastq_file.endwith(\"_R1.fastq\")][0]\n",
    "        self.short_read_fastq2_file = [fastq_file for fastq_file in os.listdir(self.short_read_dir)\n",
    "                                       if fastq_file.endwith(\"_R2.fastq\")][0]\n",
    "        # Unicycler related files\n",
    "        self.unicycler_directory = os.path.join(SUBDIRS[\"hybrid_assemblies\"], self.sample)\n",
    "        self.unicycler_assembly_file = os.path.join(self.unicycler_directory, \"assembly.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"In this code chunk we define all of the commands.\n",
    "   We could do this in the sample section, and create each function as an a attribute of an object in the sample class.\n",
    "   ... but I feel this is a little too abstract and ruins the flow of the script.\n",
    "   Not all commands will be here, there will be some cheeky manipulations occuring in the main script.\n",
    "   Particularly stuff that is exported to csvs for purpose of powerpoint presentation.\"\"\"\n",
    "\n",
    "# First up we have the pauvre command\n",
    "def run_pauvre(input_fastq_file, title, output_folder):\n",
    "    pauvre_command_options=[\"python3 $(which pauvre)\"]\n",
    "    pauvre_command_options.append(\"marginplot\")\n",
    "    pauvre_command_options.append(\"--fastq %s\" % input_fastq_file)\n",
    "    pauvre_command_options.append(\"--title 'Distribution of %s'\" % title)\n",
    "    pauvre_command = ' '.join(pauvre_command_options)\n",
    "    pauvre_proc = subprocess.Popen(pauvre_command, shell=True,\n",
    "                                     stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = pauvre_proc.communicate()\n",
    "    # Pauvre file created in the current working directory. Need to move to approrpriate directory\n",
    "    output_file = os.path.basename(input_fastq_file).replace(\".fastq\", \".png\")\n",
    "    shutil.move(output_file, output_folder)\n",
    "    \n",
    "# Next the porechop command\n",
    "def run_porechop(fastq_file, output_fastq_file, output_log_file):\n",
    "    porechop_command_options = [\"porechop\"]\n",
    "    porechop_command_options.append(\"--input %s\" % fastq_file)\n",
    "    porechop_command_options.append(\"--discard_middle\")  # Remove any reads with adapters in the middle.\n",
    "    porechop_command_options.append(\"--require_two_barcodes\")  # Remove any reads with adapters in the middle.\n",
    "    porechop_command_options.append(\"--output %s\" % output_fastq_file)\n",
    "    porechop_command_options.append(\"2> %s\" % output_log_file)\n",
    "    porechop_command = ' '.join(porechop_command_options)\n",
    "    # Run through subprocess\n",
    "    porechop_proc = subprocess.Popen(porechop_command, shell=True,\n",
    "                                     stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = porechop_proc.communicate()\n",
    "    print(stdout, stderr)\n",
    "\n",
    "# Canu\n",
    "def run_canu(prefix, directory, estimated_genome_length, input_fastq_file, canu_stderr_log)\n",
    "    canu_command_options = [\"canu\"]\n",
    "    canu_command_options.append(\"-p %s\" % sample)\n",
    "    canu_command_options.append(\"-d %s\" % sample_canu_dir)\n",
    "    canu_command_options.append(\"genomeSize=%d\" % est_genome_length)\n",
    "    canu_command_options.append(\"useGrid=false\")\n",
    "    canu_command_options.append('stopOnReadQuality=false')\n",
    "    canu_command_options.append(\"-nanopore-raw\")\n",
    "    canu_command_options.append(\"%s.all.trimmed.fastq\" % os.path.join(trimmed_dir, sample))\n",
    "    canu_command_options.append(\"2> %s\" % os.path.join(sample_canu_dir, sample + \".stderr.log\"))\n",
    "    canu_command = ' '.join(canu_command_options)\n",
    "\n",
    "    canu_proc = subprocess.Popen(canu_command, shell=True,\n",
    "                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = canu_proc.communicate()\n",
    "    print(stdout, stderr)\n",
    "    \n",
    "# Circlator\n",
    "def run_circlator(sample_name, input_contig_file, output_contig_prefix):\n",
    "    if os.path.isdir(circlator_sample_dir):\n",
    "    shutil.rmtree(circlator_sample_dir)\n",
    "    os.mkdir(circlator_sample_dir) \n",
    "    # Circlator command\n",
    "    circlator_command_options = [\"circlator minimus2\"]\n",
    "    circlator_command_options.append(input_contig_file)\n",
    "    circlator_command_options.append(output_contig_prefix)\n",
    "    circlator_command = ' '.join(circlator_command_options)\n",
    "    # Remove \n",
    "    sed_command = \"sed -i \\\"1 s/^>tig0000000\\\\d/>%s.circularised/\\\" %s\" % (sample_name, circlator_output_prefix+\".circularise.fasta\")\n",
    "    # Run commands sequentially\n",
    "    circlator_proc = subprocess.Popen(' && '.join([circlator_command, sed_command]), shell=True,\n",
    "                                                   stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "# Sam2bamalignment\n",
    "def run_bwamem_sam2bam(reference, input_fastq_file, sam_file, bam_file, bai_file):\n",
    "    # Create the bwa and samtools indexes for the draft reference\n",
    "    bwa_index_command = \"bwa index %s\" % reference\n",
    "    samtools_index_command = \"samtools faidx %s\" % reference\n",
    "    index_proc = subprocess.Popen(' && '.join([bwa_index_command, samtools_index_command]), shell=True,\n",
    "                                  stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = index_proc.communicate()\n",
    "    print(stdout, stderr)\n",
    "    \n",
    "    # Now run the bwa and sam2bam command\n",
    "    bwa_align_command = \"bwa mem -x ont2d %s %s > %s\" % (reference, input_fastq_file, sam_file)\n",
    "    \n",
    "    # Samtools view and sort command\n",
    "    samtools_view_and_sort_command = \"samtools view -bS %s | samtools sort -o %s -\" % (sam_file, bam_file)\n",
    "    \n",
    "    # Create bam index\n",
    "    bam_index_command = \"samtools index %s %s\" % (bam_file, bai_file)\n",
    "    \n",
    "    # Run all commands sequentially\n",
    "    alignment_commands = ' && '.join([bwa_align_command, samtools_view_and_sort_command,\n",
    "                                       bam_index_command])\n",
    "    alignment_proc = subprocess.Popen(alignment_commands, shell=True,\n",
    "                                      stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = alignment_proc.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(RUN_DIR)\n",
    "subdirs_list = [\"fastq\", \"pauvre\", \"trimmed\", \"canu\", \"circlator\", \"alignment\", \"illumina_data\"]\n",
    "SUBDIRS = {key,os.path.join(RUN_DIR, value) for key,value in itertools.izip(subdirs_list, subdirs_list)}\n",
    "SAMPLES = []  # List of objects of the class SAMPLE\n",
    "barcode2sample_dict = {\"barcode01\": \"JB2\",\n",
    "                       \"barcode02\": \"JB1\",\n",
    "                       \"barcode11\": \"PTS1\",\n",
    "                       \"barcode12\": \"PTS2\",\n",
    "                       \"barcode06\": \"YHC6\",\n",
    "                       \"barcode07\": \"YHC7\",\n",
    "                       \"barcode08\": \"YHC8\",\n",
    "                       \"barcode09\": \"YHC17\",\n",
    "                       \"unclassified\": \"unclassified\"}\n",
    "\n",
    "fastq_files = [fastq_file for fastq_file in os.listdir(SUBDIRS[\"fastq\"])\n",
    "               if fastq_file.startswith(\"barcode\")]\n",
    "\n",
    "# Add barcodes to the sample class\n",
    "for fastq_file in fastq_files:\n",
    "    # fastq_file barcode07.all.fastq\n",
    "    barcode = fastq_file.split(\".\")[0]\n",
    "    name = barcode2sample_dict[barcode]\n",
    "    SAMPLES.append(Sample(barcode=barcode, name=name. description=None, fastq_file=fastq_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Presentation orientated code_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Function to count the number of reads per fastq file.\n",
    "### Output to csv with the following columns:\n",
    "### Bin, barcode, num nucleotides per barcode/bin\n",
    "csv_output_file = os.path.join(PRESENTATION_DIR, \"data\", \"size_by_barcode.tsv\")\n",
    "bin_df = pd.DataFrame(columns=[\"bin\", \"sample\", \"nucleotides\"])\n",
    "for fastq_file in fastq_files:\n",
    "    # 0005_49335_plasmids.barcode07.0.fastq\n",
    "    bin_id = fastq_file.split(\"_\")[0]\n",
    "    barcode = fastq_file.split(\".\")[1]\n",
    "    # Get number of nucleotides\n",
    "    num_nucleotides = 0\n",
    "    with open(os.path.join(SUBDIRS[\"fastq\"], fastq_file), \"rU\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fastq\"):\n",
    "            num_nucleotides += len(record.seq)\n",
    "    df_as_series = pd.Series(data=[bin_id, barcode2sample_dict[barcode], num_nucleotides], index=[\"bin\", \"sample\", \"nucleotides\"])\n",
    "    bin_df = bin_df.append(df_as_series, ignore_index=True)\n",
    "bin_df.to_csv(csv_output_file, index=False, sep=\"\\t\")\n",
    "# Get minimum sample we will move the pauvre plot of this sample to the PRESENTATION_DIR\n",
    "grouped = bin_df.groupby(\"sample\")\n",
    "min_sample_name = grouped['nucleotides'].aggregate(np.sum).idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now run through qc and assembly pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the pauvre command\n",
    "for sample in SAMPLES:\n",
    "    run_pauvre(input_fastq_file=sample.fastq_path, \n",
    "               title=sample.name, \n",
    "               output_folder=SUBDIRS[\"pauvre\"])\n",
    "    \n",
    "# Copy pauvre plot of smallest file to PRESENTATION_DIR\n",
    "pauvre_min_output_plot = os.path.join(SUBDIRS[\"pauvre\"], min_sample_name+\".all.png\")\n",
    "pauvre_plot_presentation_file = os.path.join(PRESENTATION_DIR, \"images\", \"pauvre_min.png\")\n",
    "shutil.copy(pauvre_min_output_plot, pauvre_plot_presentation_file)\n",
    "                                      \n",
    "# Use porechop to trim adapters off reads\n",
    "for sample in SAMPLES:\n",
    "    run_porechop(fastq_file=sample.fastq_path, \n",
    "                 output_fastq_file=sample.fastq_file_trimmed, \n",
    "                 output_log_file=sample.trimmed_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We also need to estimate the genome lengths before we continue\n",
    "As Canu requires this as an input parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YHC17.all.trimmed.fastq\n",
      "YHC17.all.trimmed.fastq: top 5 mean: 21705. Over 10 reads. reads are: 26923 22132 22090 22090 21669 21557 21060 20027 19884 19620\n",
      "YHC6.all.trimmed.fastq\n",
      "YHC6.all.trimmed.fastq: top 5 mean: 20112. Over 4 reads. reads are: 37138 14579 14408 14326\n",
      "YHC7.all.trimmed.fastq\n",
      "YHC7.all.trimmed.fastq: top 5 mean: 15924. Over 8 reads. reads are: 19173 18436 16460 15427 15298 15181 14069 13351\n",
      "JB1.all.trimmed.fastq\n",
      "JB1.all.trimmed.fastq: top 5 mean: 8894. Over 219 reads. reads are: 22273 21469 16487 15694 15277 13740 13286 13019 12166 12154 11921 11247 11232 10685 9669 9309 9150 9040 8985 8921 8877 8874 8843 8836 8817 8800 8795 8743 8736 8717 8707 8700 8700 8686 8678 8663 8642 8640 8635 8624 8607 8604 8588 8584 8583 8580 8580 8580 8579 8577 8573 8572 8566 8564 8563 8562 8560 8560 8556 8555 8553 8553 8549 8549 8547 8547 8547 8546 8546 8545 8543 8542 8540 8540 8540 8539 8538 8536 8535 8533 8533 8532 8531 8527 8526 8526 8526 8523 8522 8521 8520 8519 8518 8516 8515 8515 8512 8510 8507 8506 8505 8505 8504 8504 8503 8502 8499 8499 8498 8498 8497 8496 8494 8491 8491 8491 8490 8489 8487 8487 8487 8485 8484 8484 8483 8482 8482 8480 8480 8479 8479 8479 8478 8477 8477 8477 8477 8476 8476 8475 8473 8471 8470 8470 8469 8466 8465 8463 8463 8462 8462 8461 8460 8460 8460 8459 8458 8455 8455 8454 8454 8453 8453 8453 8452 8451 8450 8444 8443 8442 8439 8439 8438 8436 8435 8434 8434 8434 8433 8432 8431 8431 8431 8430 8425 8425 8422 8417 8415 8414 8413 8412 8412 8408 8407 8406 8400 8400 8394 8383 8382 8382 8382 8381 8379 8379 8373 8368 8364 8363 8354 8351 8350 8350 8349 8344 8343 8341 8337\n",
      "PTS1.all.trimmed.fastq\n",
      "PTS1.all.trimmed.fastq: top 5 mean: 13987. Over 9 reads. reads are: 26269 23763 15471 13059 12720 9250 8871 8585 7899\n",
      "JB2.all.trimmed.fastq\n",
      "JB2.all.trimmed.fastq: top 5 mean: 12228. Over 20 reads. reads are: 25890 17545 16886 15725 15040 12178 12036 11694 11182 10975 10846 10509 10386 9860 9448 9292 9090 8859 8825 8310\n",
      "PTS2.all.trimmed.fastq\n",
      "PTS2.all.trimmed.fastq: top 5 mean: 13553. Over 6 reads. reads are: 38593 11277 8540 8318 8076 6515\n",
      "YHC8.all.trimmed.fastq\n",
      "YHC8.all.trimmed.fastq: top 5 mean: 27458. Over 12 reads. reads are: 47382 38608 31197 28321 24262 23008 22917 22914 22814 22716 22695 22664\n"
     ]
    }
   ],
   "source": [
    "# Estimate genome size using top five percent of reads.\n",
    "for sample in SAMPLES:\n",
    "    with open(sample.fastq_file_trimmed, \"rU\") as handle:\n",
    "        record_dict = SeqIO.to_dict(SeqIO.parse(handle, \"fastq\"))\n",
    "    number_reads = len(record_dict)\n",
    "    iterator = 0\n",
    "    number_reads_top5 = number_reads*0.05\n",
    "    cumulative_sum = 0\n",
    "    read_list = []\n",
    "    for id in sorted(record_dict, key=lambda id: len(record_dict[id].seq), reverse=True):\n",
    "        iterator += 1\n",
    "        cumulative_sum += len(record_dict[id].seq)\n",
    "        read_list.append(len(record_dict[id].seq))\n",
    "        if iterator > number_reads_top5:\n",
    "            break\n",
    "            \n",
    "    mean = cumulative_sum/iterator\n",
    "    print(\"%s: top 5 mean: %d. Over %d reads.\" % (fastq_file, mean, iterator))\n",
    "    sample.est_genome_length = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use Canu to assemble genome\n",
    "for sample in SAMPLES:\n",
    "    run_canu(prefix=sample.name,\n",
    "             directory=os.path.join(SUBDIRS[\"canu\"], sample.name)\n",
    "             estimated_genome_length=sample.est_genome_length\n",
    "             input_fastq_file=sample.fastq_file_trimmed\n",
    "             canu_stderr_log=sample.canu_log_output\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename the first tigID for each sample\n",
    "for sample in SAMPLES:\n",
    "    if os.stat(sample.canu_contig_file).st_size == 0:\n",
    "        # Failed to form contig, use tigInfoFile to get main contig out of unassembled file\n",
    "        # Open up unassembled fasta file:\n",
    "        records = SeqIO.parse(sample.canu_unassembled_fasta_file, \"fasta\")\n",
    "        # Open up tigInfo File\n",
    "        tigInfoFile = os.path.join(canu_dir, sample, sample+\".contigs.layout.tigInfo\")\n",
    "        tigInfoDF = pd.read_csv(tigInfoFile, sep=\"\\t\", header=0)\n",
    "        # Get contigs with coverage > 1\n",
    "        covered_contigs = [\"tig{:08d}\".format(contig)\n",
    "                           for contig in tigInfoDF.loc[tigInfoDF[\"coverage\"] > 1][\"#tigID\"].tolist()]\n",
    "        # write contigs with coverage > 1 to canu contig file\n",
    "        SeqIO.write([record for record in records if record.id in covered_contigs],\n",
    "                     sample.canu_contig_file, \"fasta\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run circlator minimus2 to circularise genome\n",
    "for sample in SAMPLES:\n",
    "    run_circlator(input_contig_file=sample.canu_contig_file\n",
    "                  output_contig_prefix=sample.circlator_output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Align trimmed canu reads back to circulator, we can then look at this in IGV.\n",
    "for sample in SAMPLES:\n",
    "    run_bwamem_sam2bam(reference=sample.circulator_output_fasta,\n",
    "                       input_fastq_file=sample.canu_trimmed_corrected_reads,\n",
    "                       sam_file=sample.sam_file,\n",
    "                       bam_file=sample.bam_file,\n",
    "                       bai_file=sample.bai_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more exporting to the PRESENTATION DIRECTORY\n",
    "That's the end of the pipeline folks!\n",
    "But we're not done yet.\n",
    "We will export the 'circularisation' status to the presentation directory.\n",
    "Then we will try add the unclassified reads back in by mapping them back to the genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "  sample genome_size circularised\n",
      "0   YHC8       27458        False\n",
      "1    JB2       12228         True\n",
      "2    JB1        8894         True\n",
      "3   PTS1       13987         True\n",
      "4   PTS2       13553         True\n",
      "5   YHC6       20112        False\n",
      "6   YHC7       15924         True\n",
      "7  YHC17       21705        False\n"
     ]
    }
   ],
   "source": [
    "# Test for circularisation, export to TSV\n",
    "samples = genome_lengths.iterkeys()\n",
    "circlator_dir = os.path.join(RUN_DIR, \"circlator\")\n",
    "circularised_df = pd.DataFrame(columns=[\"sample\", \"genome_size\", \"circularised\"])\n",
    "tsv_output_file = os.path.join(PRESENTATION_DIR, \"data\", \"genome_status.tsv\")\n",
    "for sample in samples:\n",
    "    circlator_sample_dir = os.path.join(circlator_dir, sample)\n",
    "    circlator_log_file = os.path.join(circlator_sample_dir, sample+\".log\")\n",
    "    # Example line in log file: tig00000001 circularised: True\n",
    "    is_circularised_command = \"grep circularised: %s | rev | cut -d' ' -f1 | rev\" % circlator_log_file\n",
    "    is_circularised_proc = subprocess.Popen(is_circularised_command, shell=True,\n",
    "                                           stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = is_circularised_proc.communicate()\n",
    "    is_circularised = stdout.rstrip()==\"True\"\n",
    "    circularised_as_seres = pd.Series(data=[sample, genome_lengths[sample], is_circularised], \n",
    "                                      index=[\"sample\", \"genome_size\", \"circularised\"])\n",
    "    circularised_df = circularised_df.append(circularised_as_seres, ignore_index=True)\n",
    "circularised_df.to_csv(tsv_output_file, index=False, sep=\"\\t\")\n",
    "print(circularised_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This block here aligns the unclassified reads to the list of circularised genomes and tries to see\n",
    "# if any of this unclassified data can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.01 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/YHC8/YHC8.circularise.fasta\\n[main] Real time: 0.022 sec; CPU: 0.019 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 69 sequences (516009 bp)...\\n[M::mem_process_seqs] Processed 69 reads in 3.809 CPU sec, 3.809 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/YHC8/YHC8.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/canu/YHC8/YHC8.trimmedReads.fasta.gz\\n[main] Real time: 3.828 sec; CPU: 3.828 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.00 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/JB2/JB2.circularise.fasta\\n[main] Real time: 0.016 sec; CPU: 0.011 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 76 sequences (489662 bp)...\\n[M::mem_process_seqs] Processed 76 reads in 0.983 CPU sec, 0.982 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/JB2/JB2.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/canu/JB2/JB2.trimmedReads.fasta.gz\\n[main] Real time: 1.000 sec; CPU: 1.000 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.00 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/JB1/JB1.circularise.fasta\\n[main] Real time: 0.017 sec; CPU: 0.012 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 41 sequences (350546 bp)...\\n[M::mem_process_seqs] Processed 41 reads in 0.775 CPU sec, 0.775 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/JB1/JB1.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/canu/JB1/JB1.trimmedReads.fasta.gz\\n[main] Real time: 0.789 sec; CPU: 0.791 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.00 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/PTS1/PTS1.circularise.fasta\\n[main] Real time: 0.015 sec; CPU: 0.009 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 67 sequences (230937 bp)...\\n[M::mem_process_seqs] Processed 67 reads in 0.495 CPU sec, 0.495 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/PTS1/PTS1.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/canu/PTS1/PTS1.trimmedReads.fasta.gz\\n[main] Real time: 0.506 sec; CPU: 0.507 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.00 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/PTS2/PTS2.circularise.fasta\\n[main] Real time: 0.011 sec; CPU: 0.005 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 46 sequences (134430 bp)...\\n[M::mem_process_seqs] Processed 46 reads in 0.330 CPU sec, 0.329 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/PTS2/PTS2.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/canu/PTS2/PTS2.trimmedReads.fasta.gz\\n[main] Real time: 0.337 sec; CPU: 0.339 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.01 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/YHC6/YHC6.circularise.fasta\\n[main] Real time: 0.114 sec; CPU: 0.019 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 41 sequences (228691 bp)...\\n[M::mem_process_seqs] Processed 41 reads in 1.494 CPU sec, 1.493 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/YHC6/YHC6.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/canu/YHC6/YHC6.trimmedReads.fasta.gz\\n[main] Real time: 1.501 sec; CPU: 1.501 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.01 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/YHC7/YHC7.circularise.fasta\\n[main] Real time: 0.026 sec; CPU: 0.020 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 64 sequences (338019 bp)...\\n[M::mem_process_seqs] Processed 64 reads in 1.781 CPU sec, 1.779 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/YHC7/YHC7.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/canu/YHC7/YHC7.trimmedReads.fasta.gz\\n[main] Real time: 1.793 sec; CPU: 1.794 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.01 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/YHC17/YHC17.circularise.fasta\\n[main] Real time: 0.018 sec; CPU: 0.014 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 61 sequences (448655 bp)...\\n[M::mem_process_seqs] Processed 61 reads in 1.980 CPU sec, 1.979 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/circlator/YHC17/YHC17.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/canu/YHC17/YHC17.trimmedReads.fasta.gz\\n[main] Real time: 2.026 sec; CPU: 1.996 sec\\n')\n"
     ]
    }
   ],
   "source": [
    "# Re-align reads using samtools\n",
    "# Create alignment dir\n",
    "samples = genome_lengths.iterkeys()\n",
    "alignment_dir = os.path.join(RUN_DIR, \"alignment\")\n",
    "if not os.path.isdir(alignment_dir):\n",
    "    os.mkdir(alignment_dir)\n",
    "# Run alignment for each sample reads    \n",
    "for sample in samples:\n",
    "    # Get trimmed canu reads\n",
    "    sample_canu_dir = os.path.join(canu_dir, sample)\n",
    "    sample_alignment_dir = os.path.join(alignment_dir, sample)\n",
    "    if os.path.isdir(sample_alignment_dir):\n",
    "        shutil.rmtree(sample_alignment_dir)\n",
    "    os.mkdir(sample_alignment_dir)\n",
    "    \n",
    "    circlator_sample_dir = os.path.join(circlator_dir, sample)\n",
    "    circlator_contig_file = os.path.join(circlator_sample_dir, sample+\".circularise.fasta\")\n",
    "\n",
    "    sam_file = os.path.join(sample_alignment_dir, sample+\".sam\")\n",
    "    bam_file = os.path.join(sample_alignment_dir, sample+\".bam\")\n",
    "    bai_file = os.path.join(sample_alignment_dir, sample+\".bai\")\n",
    "\n",
    "    if not os.path.isdir(sample_alignment_dir):\n",
    "        os.mkdir(sample_alignment_dir)\n",
    "    # Use the corrected and trimmed reads from Canu\n",
    "    trimmed_reads = os.path.join(sample_canu_dir, sample+\".trimmedReads.fasta.gz\")\n",
    "    \n",
    "    # Create the bwa and samtools indexes for the draft reference\n",
    "    bwa_index_command = \"bwa index %s\" % circlator_contig_file\n",
    "    samtools_index_command = \"samtools faidx %s\" % circlator_contig_file\n",
    "    index_proc = subprocess.Popen(' && '.join([bwa_index_command, samtools_index_command]), shell=True,\n",
    "                                  stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = index_proc.communicate()\n",
    "    print(stdout, stderr)\n",
    "    \n",
    "    # Now run the bwa and sam2bam command\n",
    "    bwa_align_command = \"bwa mem -x ont2d %s %s > %s\" % (circlator_contig_file, trimmed_reads, sam_file)\n",
    "    \n",
    "    # Samtools view and sort command\n",
    "    samtools_view_and_sort_command = \"samtools view -bS %s | samtools sort -o %s -\" % (sam_file, bam_file)\n",
    "    \n",
    "    # Create bam index\n",
    "    bam_index_command = \"samtools index %s %s\" % (bam_file, bai_file)\n",
    "    \n",
    "    # Run all commands sequentially\n",
    "    alignment_commands = ' && '.join([bwa_align_command, samtools_view_and_sort_command,\n",
    "                                       bam_index_command])\n",
    "    alignment_proc = subprocess.Popen(alignment_commands, shell=True,\n",
    "                                      stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = alignment_proc.communicate()\n",
    "    print(stdout, stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', '')\n",
      "('', '')\n",
      "('', '')\n",
      "('', '')\n",
      "('', '')\n",
      "('', '')\n",
      "('', '')\n",
      "('', '')\n"
     ]
    }
   ],
   "source": [
    "# Use the unassembled data and map to the draft genomes\n",
    "# Step 1: Create concatenated draft genome\n",
    "samples = genome_lengths.iterkeys()\n",
    "random_dir = os.path.join(RUN_DIR, \"unclassified\")\n",
    "if not os.path.isdir(random_dir):\n",
    "    os.mkdir(random_dir)\n",
    "    \n",
    "# Concatenate references into all_genomes_files\n",
    "all_draft_genomes_file = os.path.join(random_dir, \"all_draft_genomes.fna\")\n",
    "if os.path.isfile(all_draft_genomes_file):\n",
    "    os.remove(all_draft_genomes_file)\n",
    "for sample in samples:\n",
    "    # Concatenate references into all_genomes_files\n",
    "    sample_alignment_dir = os.path.join(alignment_dir, sample) \n",
    "    circlator_sample_dir = os.path.join(circlator_dir, sample)\n",
    "    circlator_contig_file = os.path.join(circlator_sample_dir, sample+\".circularise.fasta\")\n",
    "    cat_command = \"cat %s >> %s\" % (circlator_contig_file, all_draft_genomes_file)\n",
    "    cat_proc = subprocess.Popen(cat_command, shell=True,\n",
    "                                stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = cat_proc.communicate()\n",
    "    print(stdout, stderr)\n",
    "    \n",
    "# Create bwa and faidx\n",
    "bwa_index_command = \"bwa index %s\" % all_draft_genomes_file\n",
    "samtools_index_command = \"samtools faidx %s\" % all_draft_genomes_file\n",
    "index_proc = subprocess.Popen(' && '.join([bwa_index_command, samtools_index_command]), shell=True,\n",
    "                              stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout, stderr = index_proc.communicate()\n",
    "\n",
    "# Align all unclassified reads to the genome sets.\n",
    "all_unclassified_fasta_files = os.path.join(FASTQ_DIR, \"unclassified.all.fastq\")\n",
    "all_unclassified_trimmed_fasta_file = os.path.join(trimmed_dir, \"unclassified.all.trimmed.fastq\")\n",
    "sam_file = os.path.join(random_dir, \"unclassified.all.sam\")\n",
    "bam_file = os.path.join(random_dir, \"unclassified.all.bam\")\n",
    "bai_file = os.path.join(random_dir, \"unclassified.all.bai\")\n",
    "\n",
    "# But first we trim.\n",
    "porechop_command_options = [\"porechop\"]\n",
    "porechop_command_options.append(\"--input %s\" % all_unclassified_fasta_files)\n",
    "porechop_command_options.append(\"--discard_middle\")  # Remove any reads with adapters in the middle.\n",
    "porechop_command_options.append(\"--output %s\" % os.path.join(trimmed_dir, all_unclassified_trimmed_fasta_file))\n",
    "porechop_command = ' '.join(porechop_command_options)\n",
    "porechop_proc = subprocess.Popen(porechop_command, shell=True,\n",
    "                                 stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout, stderr = porechop_proc.communicate()\n",
    "\n",
    "# Now run the bwa and sam2bam command\n",
    "bwa_align_command = \"bwa mem -x ont2d %s %s > %s\" % (all_draft_genomes_file, all_unclassified_trimmed_fasta_file, sam_file)\n",
    "\n",
    "# Samtools view and sort command\n",
    "samtools_view_and_sort_command = \"samtools view -bS %s | samtools sort -o %s -\" % (sam_file, bam_file)\n",
    "    \n",
    "# Create bam index\n",
    "bam_index_command = \"samtools index %s %s\" % (bam_file, bai_file)\n",
    "# Split bam file by output\n",
    "bamtools_split_command = \"bamtools split -in %s -reference\" % bam_file\n",
    "\n",
    "# Run all commands sequentially\n",
    "alignment_commands = ' && '.join([bwa_align_command, samtools_view_and_sort_command,\n",
    "                                  bam_index_command, bamtools_split_command])\n",
    "alignment_proc = subprocess.Popen(alignment_commands, shell=True,\n",
    "                                  stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout, stderr = alignment_proc.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unclassified.all.REF_JB2.circularised.bam\n",
      "unclassified.all.REF_JB1.circularised.bam\n",
      "unclassified.all.REF_YHC8.circularised.bam\n",
      "unclassified.all.REF_PTS2.circularised.bam\n",
      "unclassified.all.REF_PTS1.circularised.bam\n",
      "unclassified.all.REF_YHC6.circularised.bam\n",
      "unclassified.all.REF_YHC7.circularised.bam\n",
      "unclassified.all.REF_YHC17.circularised.bam\n",
      "('-- Canu release v1.5\\nGFA alignments updated.\\n', '[M::bam2fq_mainloop] discarded 0 singletons\\n[M::bam2fq_mainloop] processed 181 reads\\n')\n",
      "('-- Canu release v1.5\\nGFA alignments updated.\\n', '[M::bam2fq_mainloop] discarded 0 singletons\\n[M::bam2fq_mainloop] processed 431 reads\\n')\n",
      "('-- Canu release v1.5\\nGFA alignments updated.\\n', '[M::bam2fq_mainloop] discarded 0 singletons\\n[M::bam2fq_mainloop] processed 1430 reads\\n')\n",
      "('-- Canu release v1.5\\nGFA alignments updated.\\n', '[M::bam2fq_mainloop] discarded 0 singletons\\n[M::bam2fq_mainloop] processed 95 reads\\n')\n",
      "('-- Canu release v1.5\\nGFA alignments updated.\\n', '[M::bam2fq_mainloop] discarded 0 singletons\\n[M::bam2fq_mainloop] processed 54 reads\\n')\n",
      "('-- Canu release v1.5\\nGFA alignments updated.\\n', '[M::bam2fq_mainloop] discarded 0 singletons\\n[M::bam2fq_mainloop] processed 107 reads\\n')\n",
      "('-- Canu release v1.5\\nGFA alignments updated.\\n', '[M::bam2fq_mainloop] discarded 0 singletons\\n[M::bam2fq_mainloop] processed 45 reads\\n')\n",
      "('-- Canu release v1.5\\nGFA alignments updated.\\n', '[M::bam2fq_mainloop] discarded 0 singletons\\n[M::bam2fq_mainloop] processed 95 reads\\n')\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Convert these output bam files to fastq\n",
    "bam_files = [bam_file for bam_file in os.listdir(random_dir)\n",
    "             if bam_file.endswith(\".bam\") and\n",
    "             \"unmapped\" not in bam_file and\n",
    "             \"REF\" in bam_file]\n",
    "\n",
    "# Create dictionary of bam_files\n",
    "bam_files_by_sample = {}\n",
    "for bam_file in bam_files:\n",
    "    # Bam file: unclassified.all.REF_PTS2.circularised.bam\n",
    "    print(bam_file)\n",
    "    sample = bam_file.split(\".\")[2].split(\"_\")[1]\n",
    "    bam_files_by_sample[sample] = os.path.join(random_dir, bam_file)\n",
    "\n",
    "for sample, bam_file in bam_files_by_sample.iteritems():\n",
    "    # Run bam2fastq\n",
    "    fastq_file = os.path.join(random_dir, \"unclassified.%s.fastq\" % sample)\n",
    "    bam2fastq_command = \"samtools bam2fq -O %s | seqtk seq > %s\" % (bam_file, fastq_file)\n",
    "    \n",
    "    # Create concatenated fastq file that appends reads from trimmed directory\n",
    "    original_trimmed_file = os.path.join(trimmed_dir, sample+\".all.trimmed.fastq\")\n",
    "    \n",
    "    cat_command = \"cat %s >> %s\" % (original_trimmed_file, fastq_file)\n",
    "    \n",
    "    # Run this again through canu\n",
    "    sample_canu_dir = os.path.join(random_dir, \"canu_%s\" % sample)\n",
    "    canu_prefix = \"retry_canu_%s\" % sample\n",
    "    if os.path.isdir(sample_canu_dir):\n",
    "        shutil.rmtree(sample_canu_dir)\n",
    "    os.mkdir(sample_canu_dir)\n",
    "    \n",
    "    canu_command_options = [\"canu\"]\n",
    "    canu_command_options.append(\"-p %s\" % canu_prefix)\n",
    "    canu_command_options.append(\"-d %s\" % sample_canu_dir)\n",
    "    canu_command_options.append(\"genomeSize=%d\" % genome_lengths[sample])\n",
    "    canu_command_options.append(\"useGrid=false\")\n",
    "    canu_command_options.append('stopOnReadQuality=false')\n",
    "    canu_command_options.append(\"-nanopore-raw\")\n",
    "    canu_command_options.append(\"%s\" % fastq_file)\n",
    "    canu_command_options.append(\"2> %s\" % os.path.join(sample_canu_dir, sample + \".stderr.log\"))\n",
    "    canu_command = ' '.join(canu_command_options)\n",
    "    rerun_pipeline = subprocess.Popen(' && '.join([bam2fastq_command, cat_command, canu_command]), \n",
    "                                      shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = rerun_pipeline.communicate()\n",
    "    print(stdout, stderr)\n",
    "    contigFile = os.path.join(sample_canu_dir, canu_prefix+\".contigs.fasta\")\n",
    "    if os.stat(contigFile).st_size == 0:\n",
    "        # Failed to form contig, use tigInfoFile to get main contig out of unassembled file\n",
    "        unassembled_fasta_file = os.path.join(sample_canu_dir, canu_prefix+\".unassembled.fasta\")\n",
    "        # Open up unassembled fasta file:\n",
    "        records = SeqIO.parse(unassembled_fasta_file, \"fasta\")\n",
    "        # Open up tigInfo File\n",
    "        tigInfoFile = os.path.join(sample_canu_dir, canu_prefix+\".contigs.layout.tigInfo\")\n",
    "        tigInfoDF = pd.read_csv(tigInfoFile, sep=\"\\t\", header=0)\n",
    "        # Get contigs with coverage > 1\n",
    "        covered_contigs = [\"tig{:08d}\".format(contig)\n",
    "                           for contig in tigInfoDF.loc[tigInfoDF[\"coverage\"] > 1][\"#tigID\"].tolist()]\n",
    "        # write contigs to contigFile\n",
    "        #with open(contigFile, \"w\") as output_handle:\n",
    "         #   SeqIO.write(record for, output_handle, \"fasta\")\n",
    "        #for contig in covered_contigs:\n",
    "        #    print(record_dict[\"{:08d}\".format(contig)]))\n",
    "        SeqIO.write([record for record in records if record.id in covered_contigs],\n",
    "                    contigFile, \"fasta\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', '')\n",
      "('', '')\n",
      "('', '')\n",
      "('', '')\n",
      "('', '')\n",
      "('', '')\n",
      "('', '')\n",
      "('', '')\n"
     ]
    }
   ],
   "source": [
    "# Now run circulator to circularise the genome and generate a consensus\n",
    "samples = genome_lengths.iterkeys()\n",
    "circlator_dir = os.path.join(random_dir, \"circlator\")\n",
    "if not os.path.isdir(circlator_dir):\n",
    "    os.mkdir(circlator_dir)\n",
    "for sample in samples:\n",
    "    # Retrieve necessary files\n",
    "    sample_canu_dir = os.path.join(random_dir, \"canu_%s\" % sample)\n",
    "    contigFile = os.path.join(sample_canu_dir, \"retry_canu_\"+sample+\".contigs.fasta\")\n",
    "    circlator_sample_dir = os.path.join(circlator_dir, sample)\n",
    "    circlator_output_prefix = os.path.join(circlator_sample_dir, sample)\n",
    "    # Output directory must not exist\n",
    "    if os.path.isdir(circlator_sample_dir):\n",
    "        shutil.rmtree(circlator_sample_dir)\n",
    "    os.mkdir(circlator_sample_dir) \n",
    "    # Circlator command\n",
    "    circlator_command_options = [\"circlator minimus2\"]\n",
    "    circlator_command_options.append(contigFile)\n",
    "    circlator_command_options.append(circlator_output_prefix)\n",
    "    circlator_command = ' '.join(circlator_command_options)\n",
    "    \n",
    "    # Need to replace top line \">tig00000001.circularised\" with actual name.\n",
    "    # Can use sed command to do this.\n",
    "    sed_command = \"sed -i \\\"1 s/^.*$/>%s.circularised/\\\" %s\" % (sample, circlator_output_prefix+\".circularise.fasta\")\n",
    "    \n",
    "    circlator_proc = subprocess.Popen(' && '.join([circlator_command, sed_command]), shell=True,\n",
    "                                                   stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = circlator_proc.communicate()\n",
    "    print(stdout, stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.01 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.00 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/YHC8/YHC8.circularise.fasta\\n[main] Real time: 0.045 sec; CPU: 0.023 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 113 sequences (707415 bp)...\\n[M::mem_process_seqs] Processed 113 reads in 6.151 CPU sec, 6.150 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/YHC8/YHC8.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/canu_YHC8/retry_canu_YHC8.trimmedReads.fasta.gz\\n[main] Real time: 6.172 sec; CPU: 6.171 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.00 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/JB2/JB2.circularise.fasta\\n[main] Real time: 0.019 sec; CPU: 0.011 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 70 sequences (489148 bp)...\\n[M::mem_process_seqs] Processed 70 reads in 1.078 CPU sec, 1.078 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/JB2/JB2.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/canu_JB2/retry_canu_JB2.trimmedReads.fasta.gz\\n[main] Real time: 1.095 sec; CPU: 1.096 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.00 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/JB1/JB1.circularise.fasta\\n[main] Real time: 0.043 sec; CPU: 0.012 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 41 sequences (351966 bp)...\\n[M::mem_process_seqs] Processed 41 reads in 1.219 CPU sec, 1.218 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/JB1/JB1.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/canu_JB1/retry_canu_JB1.trimmedReads.fasta.gz\\n[main] Real time: 1.241 sec; CPU: 1.233 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.00 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/PTS1/PTS1.circularise.fasta\\n[main] Real time: 0.032 sec; CPU: 0.009 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 84 sequences (295500 bp)...\\n[M::mem_process_seqs] Processed 84 reads in 0.637 CPU sec, 0.636 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/PTS1/PTS1.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/canu_PTS1/retry_canu_PTS1.trimmedReads.fasta.gz\\n[main] Real time: 0.650 sec; CPU: 0.650 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.00 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/PTS2/PTS2.circularise.fasta\\n[main] Real time: 0.032 sec; CPU: 0.008 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 62 sequences (198802 bp)...\\n[M::mem_process_seqs] Processed 62 reads in 0.809 CPU sec, 0.807 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/PTS2/PTS2.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/canu_PTS2/retry_canu_PTS2.trimmedReads.fasta.gz\\n[main] Real time: 0.815 sec; CPU: 0.815 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.00 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/YHC6/YHC6.circularise.fasta\\n[main] Real time: 0.015 sec; CPU: 0.008 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 71 sequences (319346 bp)...\\n[M::mem_process_seqs] Processed 71 reads in 1.431 CPU sec, 1.431 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/YHC6/YHC6.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/canu_YHC6/retry_canu_YHC6.trimmedReads.fasta.gz\\n[main] Real time: 1.440 sec; CPU: 1.441 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.00 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.00 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/YHC7/YHC7.circularise.fasta\\n[main] Real time: 0.035 sec; CPU: 0.012 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 80 sequences (437795 bp)...\\n[M::mem_process_seqs] Processed 80 reads in 2.005 CPU sec, 2.004 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/YHC7/YHC7.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/canu_YHC7/retry_canu_YHC7.trimmedReads.fasta.gz\\n[main] Real time: 2.017 sec; CPU: 2.017 sec\\n')\n",
      "('', '[bwa_index] Pack FASTA... 0.00 sec\\n[bwa_index] Construct BWT for the packed sequence...\\n[bwa_index] 0.01 seconds elapse.\\n[bwa_index] Update BWT... 0.00 sec\\n[bwa_index] Pack forward-only FASTA... 0.00 sec\\n[bwa_index] Construct SA from BWT and Occ... 0.00 sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa index /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/YHC17/YHC17.circularise.fasta\\n[main] Real time: 0.022 sec; CPU: 0.021 sec\\n')\n",
      "('', '[M::bwa_idx_load_from_disk] read 0 ALT contigs\\n[M::process] read 81 sequences (623230 bp)...\\n[M::mem_process_seqs] Processed 81 reads in 3.002 CPU sec, 3.001 real sec\\n[main] Version: 0.7.15-r1140\\n[main] CMD: bwa mem -x ont2d /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/circlator/YHC17/YHC17.circularise.fasta /data/Bioinfo/bioinfo-proj-alexis/2017_07_09_PLASMIDS_BARCODED/unclassified/canu_YHC17/retry_canu_YHC17.trimmedReads.fasta.gz\\n[main] Real time: 3.022 sec; CPU: 3.022 sec\\n')\n"
     ]
    }
   ],
   "source": [
    "# Create index and realign trimmed reads to the reference genome.\n",
    "# Re-align reads using samtools\n",
    "# Create alignment dir\n",
    "samples = genome_lengths.iterkeys()\n",
    "alignment_dir = os.path.join(random_dir, \"alignment\")\n",
    "if not os.path.isdir(alignment_dir):\n",
    "    os.mkdir(alignment_dir)\n",
    "# Run alignment for each sample reads    \n",
    "for sample in samples:\n",
    "    # Get trimmed canu reads\n",
    "    sample_canu_dir = os.path.join(random_dir, \"canu_%s\" % sample)\n",
    "    sample_alignment_dir = os.path.join(alignment_dir, sample)\n",
    "    if os.path.isdir(sample_alignment_dir):\n",
    "        shutil.rmtree(sample_alignment_dir)\n",
    "    os.mkdir(sample_alignment_dir)\n",
    "    \n",
    "    circlator_sample_dir = os.path.join(circlator_dir, sample)\n",
    "    circlator_contig_file = os.path.join(circlator_sample_dir, sample+\".circularise.fasta\")\n",
    "\n",
    "    sam_file = os.path.join(sample_alignment_dir, sample+\".sam\")\n",
    "    bam_file = os.path.join(sample_alignment_dir, sample+\".bam\")\n",
    "    bai_file = os.path.join(sample_alignment_dir, sample+\".bai\")\n",
    "\n",
    "    if not os.path.isdir(sample_alignment_dir):\n",
    "        os.mkdir(sample_alignment_dir)\n",
    "    # Use the corrected and trimmed reads from Canu\n",
    "    trimmed_reads = os.path.join(sample_canu_dir, \"retry_canu_\"+sample+\".trimmedReads.fasta.gz\")\n",
    "    \n",
    "    # Create the bwa and samtools indexes for the draft reference\n",
    "    bwa_index_command = \"bwa index %s\" % circlator_contig_file\n",
    "    samtools_index_command = \"samtools faidx %s\" % circlator_contig_file\n",
    "    index_proc = subprocess.Popen(' && '.join([bwa_index_command, samtools_index_command]), shell=True,\n",
    "                                  stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = index_proc.communicate()\n",
    "    print(stdout, stderr)\n",
    "    \n",
    "    # Now run the bwa and sam2bam command\n",
    "    bwa_align_command = \"bwa mem -x ont2d %s %s > %s\" % (circlator_contig_file, trimmed_reads, sam_file)\n",
    "    \n",
    "    # Samtools view and sort command\n",
    "    samtools_view_and_sort_command = \"samtools view -bS %s | samtools sort -o %s -\" % (sam_file, bam_file)\n",
    "    \n",
    "    # Create bam index\n",
    "    bam_index_command = \"samtools index %s %s\" % (bam_file, bai_file)\n",
    "    \n",
    "    # Run all commands sequentially\n",
    "    alignment_commands = ' && '.join([bwa_align_command, samtools_view_and_sort_command,\n",
    "                                       bam_index_command])\n",
    "    alignment_proc = subprocess.Popen(alignment_commands, shell=True,\n",
    "                                      stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = alignment_proc.communicate()\n",
    "    print(stdout, stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "  sample genome_size circularised\n",
      "0   YHC8       27458         True\n",
      "1    JB2       12228         True\n",
      "2    JB1        8894         True\n",
      "3   PTS1       13987         True\n",
      "4   PTS2       13553         True\n",
      "5   YHC6       20112        False\n",
      "6   YHC7       15924         True\n",
      "7  YHC17       21705        False\n"
     ]
    }
   ],
   "source": [
    "# Test for circularisation, export to TSV\n",
    "samples = genome_lengths.iterkeys()\n",
    "circlator_dir = os.path.join(random_dir, \"circlator\")\n",
    "circularised_df = pd.DataFrame(columns=[\"sample\", \"genome_size\", \"circularised\"])\n",
    "tsv_output_file = os.path.join(PRESENTATION_DIR, \"data\", \"using_unclassified_data_genome_status.tsv\")\n",
    "for sample in samples:\n",
    "    circlator_sample_dir = os.path.join(circlator_dir, sample)\n",
    "    circlator_log_file = os.path.join(circlator_sample_dir, sample+\".log\")\n",
    "    # Example line in log file: tig00000001 circularised: True\n",
    "    is_circularised_command = \"grep circularised: %s | rev | cut -d' ' -f1 | rev\" % circlator_log_file\n",
    "    is_circularised_proc = subprocess.Popen(is_circularised_command, shell=True,\n",
    "                                           stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = is_circularised_proc.communicate()\n",
    "    is_circularised = stdout.rstrip()==\"True\"\n",
    "    print(is_circularised)\n",
    "    circularised_as_seres = pd.Series(data=[sample, genome_lengths[sample], is_circularised], \n",
    "                                      index=[\"sample\", \"genome_size\", \"circularised\"])\n",
    "    circularised_df = circularised_df.append(circularised_as_seres, ignore_index=True)\n",
    "circularised_df.to_csv(tsv_output_file, index=False, sep=\"\\t\")\n",
    "print(circularised_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
